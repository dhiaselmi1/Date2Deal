import json
import os
from datetime import datetime
from typing import Dict, List, Optional
import re
import requests
import glob  # Ensure glob is imported for pattern matching


class YouTubeAnalysisAgent:
    GEMINI_API_KEY = "AIzaSyAcUgGfaSrzt7X11r-ree0X70aOK7VLj2g"

    def __init__(self):
        if not self.GEMINI_API_KEY or self.GEMINI_API_KEY == "VOTRE_CLÃ‰_API_GEMINI_ICI":
            raise ValueError(
                "ClÃ© API Gemini requise. Veuillez remplacer 'VOTRE_CLÃ‰_API_GEMINI_ICI' par votre clÃ© rÃ©elle.")
        print("Agent d'analyse YouTube initialisÃ© avec la clÃ© API Gemini.")

    def load_latest_json_data(self) -> Optional[Dict]:
        """
        Charge le fichier JSON le plus rÃ©cent gÃ©nÃ©rÃ© par youtube_search.py ou le script prÃ©cÃ©dent.
        Recherche les fichiers dans le rÃ©pertoire du script agent_youtube.py.

        Returns:
            Dictionnaire contenant les donnÃ©es extraites ou None si erreur
        """
        try:
            print("ğŸ” Recherche du fichier JSON le plus rÃ©cent...")

            # Get the directory of the current script (agent_youtube.py)
            script_dir = os.path.dirname(os.path.abspath(__file__))

            # Search for files using glob with the script's directory
            search_pattern_old = os.path.join(script_dir, 'youtube_results_*.json')
            search_pattern_new = os.path.join(script_dir, 'youtube_search_*.json')

            json_files_old_format = glob.glob(search_pattern_old)
            json_files_new_format = glob.glob(search_pattern_new)

            all_json_files = sorted(json_files_old_format + json_files_new_format, key=os.path.getmtime, reverse=True)

            if not all_json_files:
                print("âŒ Aucun fichier JSON de rÃ©sultats YouTube trouvÃ© dans le rÃ©pertoire du script.")
                print(f"ğŸ’¡ VÃ©rifiÃ© dans : {script_dir}")
                print("ğŸ’¡ Assurez-vous d'avoir exÃ©cutÃ© le script de recherche et de sauvegarde d'abord.")
                return None

            latest_file = all_json_files[0]
            print(f"ğŸ“„ Fichier le plus rÃ©cent trouvÃ©: {latest_file}")

            # Read JSON data
            with open(latest_file, 'r', encoding='utf-8') as f:
                raw_data_from_file = json.load(f)

            processed_data = {}
            # Detect JSON file format
            if isinstance(raw_data_from_file, dict) and 'videos' in raw_data_from_file:
                processed_data['search_query'] = raw_data_from_file.get('search_query', 'Inconnu')
                processed_data['search_date'] = raw_data_from_file.get('search_date', 'Inconnue')
                processed_data['videos'] = raw_data_from_file.get('videos', [])
            elif isinstance(raw_data_from_file, list):
                # This is the old format (direct list of videos)
                processed_data['videos'] = raw_data_from_file
                # Deduce search_query and search_date from filename for old format
                search_query_from_filename = ""
                if latest_file.startswith('youtube_results_'):
                    parts = os.path.basename(latest_file).replace('youtube_results_', '').replace('.json', '').split(
                        '_')
                    if len(parts) > 2 and re.match(r'\d{8}', parts[-2]) and re.match(r'\d{6}', parts[-1]):
                        search_query_from_filename = ' '.join(parts[:-2])
                    else:
                        search_query_from_filename = ' '.join(parts)
                processed_data['search_query'] = search_query_from_filename.replace('_', ' ').strip()
                processed_data['search_date'] = datetime.fromtimestamp(os.path.getctime(latest_file)).strftime(
                    "%Y-%m-%d %H:%M:%S")
            else:
                print(f"âŒ Format de fichier JSON inattendu: {latest_file}")
                return None

            print(f"âœ… DonnÃ©es chargÃ©es: {len(processed_data.get('videos', []))} vidÃ©os")
            print(f"ğŸ“… Date de recherche: {processed_data.get('search_date', 'Inconnue')}")
            print(f"ğŸ” Terme recherchÃ© (dÃ©duit du fichier): '{processed_data.get('search_query', 'Inconnu')}'")

            return processed_data

        except json.JSONDecodeError as e:
            print(f"âŒ Erreur lors du dÃ©codage JSON: {e}")
            return None
        except Exception as e:
            print(f"âŒ Erreur lors du chargement des donnÃ©es: {e}")
            return None

    def clean_and_prepare_data(self, raw_data: Dict) -> str:
        """
        Nettoie et prÃ©pare les donnÃ©es pour l'analyse LLM

        Args:
            raw_data: DonnÃ©es brutes du scraping YouTube

        Returns:
            Texte formatÃ© pour le LLM
        """
        if not raw_data or not raw_data.get('videos'):
            return "Aucune donnÃ©e vidÃ©o disponible."

        print("ğŸ§¹ Nettoyage et prÃ©paration des donnÃ©es...")

        formatted_text = f"RECHERCHE YOUTUBE: {raw_data['search_query']}\n"
        formatted_text += f"DATE DE RECHERCHE: {raw_data['search_date']}\n"
        formatted_text += f"NOMBRE DE VIDÃ‰OS ANALYSÃ‰ES: {len(raw_data['videos'])}\n\n"

        videos_with_subtitles = sum(1 for video in raw_data['videos'] if
                                    isinstance(video, dict) and video.get('subtitles_available', False) and video.get(
                                        'full_speech'))
        formatted_text += f"VIDÃ‰OS AVEC SOUS-TITRES DISPONIBLES: {videos_with_subtitles}/{len(raw_data['videos'])}\n\n"

        for i, video in enumerate(raw_data['videos'], 1):
            if not isinstance(video, dict):
                print(
                    f"âš ï¸ Avertissement: L'Ã©lÃ©ment {i} dans la liste des vidÃ©os n'est pas un dictionnaire et sera ignorÃ©: {video}")
                continue

            formatted_text += f"=== VIDÃ‰O {i} ===\n"
            formatted_text += f"Titre: {video.get('title', 'Titre non disponible')}\n"
            formatted_text += f"ID VidÃ©o: {video.get('video_id', 'ID non disponible')}\n"
            formatted_text += f"URL: {video.get('url', 'URL non disponible')}\n"

            if video.get('subtitles_available', False) and video.get('full_speech'):
                clean_speech = self._clean_subtitle_text(video['full_speech'])
                formatted_text += f"Contenu (sous-titres): {clean_speech}\n"
                formatted_text += f"Longueur du contenu: {len(clean_speech)} caractÃ¨res\n"
            else:
                error_msg = video.get('error', 'Raison inconnue')
                formatted_text += f"Contenu: Sous-titres non disponibles ({error_msg})\n"

            formatted_text += "\n" + "-" * 80 + "\n\n"

        print(f"âœ… DonnÃ©es prÃ©parÃ©es: {len(formatted_text)} caractÃ¨res au total")
        return formatted_text

    def _clean_subtitle_text(self, text: str) -> str:
        if not text:
            return ""

        text = re.sub(r'&#\d+;', '', text)
        text = re.sub(r'&[a-zA-Z]+;', '', text)
        text = re.sub(r'&[a-zA-Z0-9#]+;', '', text)

        text = text.replace('&#39;', "'").replace('&quot;', '"').replace('&amp;', '&')

        text = re.sub(r'\b(\w+)(\s+\1\b)+', r'\1', text)

        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'\n+', ' ', text)
        text = re.sub(r'\t+', ' ', text)

        text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)

        if len(text) > 12000:
            text = text[:12000] + "... [TEXTE TRONQUÃ‰]"

        return text.strip()

    def analyze_with_llm(self, prepared_data: str, person_focus: str = None) -> str:
        try:
            print("ğŸ¤– Analyse en cours avec le LLM (Gemini)...")

            focus_text = person_focus if person_focus else "la personnalitÃ© ou le sujet principal"

            system_instruction = f"""Tu es un analyste expert spÃ©cialisÃ© dans l'analyse de contenu YouTube et le profiling de personnalitÃ©s. 
                Ta mission est d'analyser les transcriptions de vidÃ©os pour crÃ©er un profil complet, dÃ©taillÃ© et professionnel de {focus_text}.

                INSTRUCTIONS DÃ‰TAILLÃ‰ES:
                1. Analyse TOUS les contenus disponibles avec attention.
                2. Extrait TOUTES les informations pertinentes sur {focus_text}.
                3. Distingue clairement les FAITS des OPINIONS.
                4. Identifie les patterns de comportement et de communication.
                5. Note les Ã©volutions dans le temps si dÃ©tectÃ©es.
                6. CrÃ©e une synthÃ¨se cohÃ©rente, complÃ¨te et bien structurÃ©e.
                7. Utilise des citations directes quand c'est pertinent.
                8. Indique le niveau de confiance pour chaque information.

                FORMAT DE RÃ‰PONSE OBLIGATOIRE:
                # PROFIL COMPLET DE {focus_text.upper()}

                ## ğŸ¯ RÃ‰SUMÃ‰ EXÃ‰CUTIF
                [SynthÃ¨se complÃ¨te en 3-4 phrases qui capture l'essence de la personne/sujet]

                ## ğŸ“‹ INFORMATIONS BIOGRAPHIQUES
                - **Nom complet:** [Si mentionnÃ©]
                - **Ã‚ge/Date de naissance:** [Si mentionnÃ©]
                - **Origine gÃ©ographique:** [Si mentionnÃ©]
                - **Formation:** [Si mentionnÃ©]
                - **Parcours personnel:** [Ã‰lÃ©ments de vie personnelle mentionnÃ©s]

                ## ğŸ’¼ ACTIVITÃ‰S PROFESSIONNELLES
                - **MÃ©tier principal:** [Profession actuelle]
                - **Projets en cours:** [Projets mentionnÃ©s]
                - **Collaborations:** [Partenaires, Ã©quipes]
                - **RÃ©alisations:** [SuccÃ¨s, accomplissements]
                - **Objectifs futurs:** [Projets Ã  venir mentionnÃ©s]

                ## ğŸ­ PERSONNALITÃ‰ ET STYLE
                - **Traits de caractÃ¨re:** [PersonnalitÃ© observÃ©e]
                - **Style de communication:** [FaÃ§on de s'exprimer]
                - **Humour et ton:** [Type d'humour, ambiance]
                - **Valeurs exprimÃ©es:** [Principes, valeurs mentionnÃ©es]
                - **Rapport au public:** [Relation avec l'audience]

                ## ğŸ”¥ CENTRES D'INTÃ‰RÃŠT ET EXPERTISE
                - **Sujets de prÃ©dilection:** [ThÃ¨mes favoris rÃ©currents]
                - **Domaines d'expertise:** [CompÃ©tences dÃ©montrÃ©es]
                - **Passions personnelles:** [Hobbies, intÃ©rÃªts]
                - **Tendances rÃ©currentes:** [Sujets qui reviennent souvent]

                ## ğŸ’­ OPINIONS ET POSITIONS
                - **Prises de position:** [Opinions clairement exprimÃ©es]
                - **Controverses:** [Sujets sensibles abordÃ©s]
                - **Ã‰volutions d'opinion:** [Changements dÃ©tectÃ©s]
                - **Nuances:** [SubtilitÃ©s dans les positions]

                ## ğŸ¬ ANALYSE DU CONTENU VIDÃ‰O
                - **Nombre de vidÃ©os analysÃ©es:** [Statistique]
                - **ThÃ¨mes principaux:** [Sujets les plus abordÃ©s]
                - **Ã‰volution du contenu:** [Changements dans le temps]
                - **QualitÃ© des informations:** [FiabilitÃ© des sous-titres]
                - **Citations marquantes:** [Phrases importantes extraites]

                ## âš ï¸ NOTES MÃ‰THODOLOGIQUES
                - **Sources d'information:** [VidÃ©os analysÃ©es]
                - **Limites de l'analyse:** [Ce qui manque]
                - **Niveau de confiance:** [FiabilitÃ© des informations]
                - **Recommandations:** [Pour une analyse plus poussÃ©e]
                """

            user_prompt_full = f"""{system_instruction}

Voici les donnÃ©es extraites des vidÃ©os YouTube Ã  analyser en dÃ©tail:

{prepared_data}

Analyse ces contenus de maniÃ¨re EXHAUSTIVE et fournis une synthÃ¨se COMPLÃˆTE selon les instructions. N'omets aucune information importante et sois aussi dÃ©taillÃ© que possible."""

            payload = {
                "contents": [
                    {
                        "role": "user",
                        "parts": [{"text": user_prompt_full}]
                    }
                ],
                "generationConfig": {
                    "temperature": 0.2,
                    "topP": 0.9,
                    "maxOutputTokens": 3000
                }
            }

            gemini_api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={self.GEMINI_API_KEY}"

            response = requests.post(gemini_api_url, headers={'Content-Type': 'application/json'}, json=payload)
            response.raise_for_status()

            gemini_response = response.json()

            analysis = ""
            if gemini_response and gemini_response.get('candidates'):
                for candidate in gemini_response['candidates']:
                    if candidate.get('content') and candidate['content'].get('parts'):
                        for part in candidate['content']['parts']:
                            if part.get('text'):
                                analysis += part['text']

            if not analysis:
                print(f"âš ï¸ La rÃ©ponse de Gemini ne contient pas de texte. RÃ©ponse brute: {gemini_response}")
                return "Erreur: Le modÃ¨le Gemini n'a pas retournÃ© de texte analysÃ©."

            print("âœ… Analyse LLM (Gemini) terminÃ©e avec succÃ¨s")
            return analysis

        except requests.exceptions.HTTPError as errh:
            print(f"âŒ Erreur HTTP lors de l'appel Ã  l'API Gemini : {errh}")
            print(f"DÃ©tails de la rÃ©ponse : {response.text}")
            return f"Erreur lors de l'analyse: Erreur HTTP - {errh}"
        except requests.exceptions.RequestException as err:
            print(f"âŒ Erreur de RequÃªte lors de l'appel Ã  l'API Gemini : {err}")
            return f"Erreur lors de l'analyse: Erreur de RequÃªte - {err}"
        except json.JSONDecodeError:
            print(f"âŒ Erreur : Impossible de dÃ©coder la rÃ©ponse JSON de l'API Gemini. RÃ©ponse brute : {response.text}")
            return "Erreur lors de l'analyse: Erreur de dÃ©codage JSON de la rÃ©ponse Gemini."
        except Exception as e:
            print(f"âŒ Erreur inattendue lors de l'analyse LLM : {e}")
            return f"Erreur lors de l'analyse: {str(e)}"

    def save_analysis(self, analysis: str, original_search_term: str) -> str:
        """
        Sauvegarde l'analyse dans un fichier Markdown
        Sauvegarde le fichier dans le rÃ©pertoire du script agent_youtube.py.

        Args:
            analysis: Texte de l'analyse
            original_search_term: Terme de recherche original

        Returns:
            Nom du fichier sauvegardÃ©
        """
        script_dir = os.path.dirname(os.path.abspath(__file__))
        safe_term = "".join(c for c in original_search_term if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_term = safe_term.replace(' ', '_')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"youtube_analysis_{safe_term}_{timestamp}.md"

        full_file_path = os.path.join(script_dir, filename)

        try:
            with open(full_file_path, 'w', encoding='utf-8') as f:
                f.write(f"# Analyse YouTube ComplÃ¨te - {original_search_term}\n\n")
                f.write(f"**Date de gÃ©nÃ©ration:** {datetime.now().strftime('%d/%m/%Y Ã  %H:%M:%S')}\n\n")
                f.write(f"**Terme de recherche original:** {original_search_term}\n\n")
                f.write("---\n\n")
                f.write(analysis)
                f.write("\n\n---\n\n")
                f.write("*Analyse gÃ©nÃ©rÃ©e automatiquement par YouTubeAnalysisAgent (avec Gemini)*\n")

            print(f"ğŸ’¾ Analyse sauvegardÃ©e dans: {full_file_path}")
            return full_file_path

        except Exception as e:
            print(f"âŒ Erreur lors de la sauvegarde: {e}")
            return ""

    def run_complete_analysis(self, person_focus: str = None) -> Optional[str]:
        """
        ExÃ©cute l'analyse complÃ¨te: chargement -> nettoyage -> analyse LLM -> sauvegarde

        Args:
            person_focus: Nom de la personne Ã  analyser (optionnel)

        Returns:
            Nom du fichier d'analyse gÃ©nÃ©rÃ© ou None si erreur
        """
        print("ğŸš€ DÃ©marrage de l'analyse complÃ¨te des donnÃ©es YouTube")
        print("=" * 70)

        # 1. Chargement des donnÃ©es JSON
        raw_data = self.load_latest_json_data()
        if not raw_data:
            print("âŒ Impossible de charger les donnÃ©es YouTube")
            return None

        search_term = raw_data.get('search_query', 'Recherche inconnue')
        print(f"âœ… DonnÃ©es chargÃ©es pour la recherche: '{search_term}'")

        # 2. Nettoyage et prÃ©paration des donnÃ©es
        prepared_data = self.clean_and_prepare_data(raw_data)
        if not prepared_data or "Aucune donnÃ©e vidÃ©o disponible." in prepared_data:
            print("âŒ Aucune donnÃ©e utilisable aprÃ¨s nettoyage ou aucun sous-titre disponible pour l'analyse.")
            return None

        print("âœ… DonnÃ©es nettoyÃ©es et prÃ©parÃ©es pour l'analyse")

        # 3. Analyse avec LLM
        effective_person_focus = person_focus if person_focus else search_term
        print(f"ğŸ¯ Focus de l'analyse: {effective_person_focus}")
        analysis = self.analyze_with_llm(prepared_data, effective_person_focus)

        if "Erreur lors de l'analyse" in analysis:
            print("âŒ Erreur lors de l'analyse LLM")
            return None

        # 4. Sauvegarde
        filename = self.save_analysis(analysis, search_term)
        if not filename:
            print("âŒ Erreur lors de la sauvegarde")
            return None

        print("=" * 70)
        print("ğŸ‰ ANALYSE TERMINÃ‰E AVEC SUCCÃˆS!")
        print(f"ğŸ“„ Fichier gÃ©nÃ©rÃ©: {filename}")
        print(f"ğŸ“Š Longueur de l'analyse: {len(analysis)} caractÃ¨res")

        print("\n" + "=" * 70)
        print("ğŸ“‹ APERÃ‡U DE L'ANALYSE:")
        print("=" * 70)


        return filename


def main():
    """
    Fonction principale pour utiliser l'agent
    """
    print("ğŸ¬ AGENT D'ANALYSE YOUTUBE - DONNÃ‰ES EXISTANTES")
    print("=" * 60)
    print("Ce programme analyse le fichier JSON le plus rÃ©cent")
    print("gÃ©nÃ©rÃ© par le script de recherche YouTube.")
    print("=" * 60)

    try:
        agent = YouTubeAnalysisAgent()

        raw_data = agent.load_latest_json_data()
        if not raw_data:
            print("âŒ Impossible de charger les donnÃ©es YouTube. L'analyse ne peut pas continuer.")
            return

        person_focus = raw_data.get('search_query', 'Analyse gÃ©nÃ©rale')
        print(f"\nğŸ‘¤ Focus de l'analyse dÃ©duit du fichier: '{person_focus}'")

        print(f"\nğŸ”„ Lancement de l'analyse...")
        print(f"ğŸ“Š Analyse du contenu avec focus sur: {person_focus}")

        result = agent.run_complete_analysis(person_focus)

        if result:
            print(f"\nâœ… Analyse terminÃ©e avec succÃ¨s!")
            print(f"ğŸ“ Consultez le fichier: {result}")
            print("\nğŸ’¡ Le fichier contient une analyse complÃ¨te et dÃ©taillÃ©e.")
        else:
            print("\nâŒ L'analyse a Ã©chouÃ©. VÃ©rifiez les logs ci-dessus.")
            print("ğŸ’¡ Assurez-vous qu'un fichier JSON de rÃ©sultats existe (exÃ©cutez le script de recherche d'abord).")

    except ValueError as e:
        print(f"âŒ Erreur de configuration: {e}")
    except Exception as e:
        print(f"âŒ Erreur inattendue: {e}")


if __name__ == "__main__":
    main()
